

<!DOCTYPE html>


<html lang="en" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.18.1: http://docutils.sourceforge.net/" />

    <title>Sheet 3.2: Optimizing an RSA model &#8212; Neural Pragmatic Natural Language Generation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../_static/styles/theme.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/bootstrap.css?digest=e353d410970836974a52" rel="stylesheet" />
<link href="../_static/styles/pydata-sphinx-theme.css?digest=e353d410970836974a52" rel="stylesheet" />

  
  <link href="../_static/vendor/fontawesome/6.1.2/css/all.min.css?digest=e353d410970836974a52" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../_static/vendor/fontawesome/6.1.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../_static/pygments.css" />
    <link rel="stylesheet" href="../_static/styles/sphinx-book-theme.css?digest=14f4ca6b54d191a8c7657f6c759bf11a5fb86285" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../_static/scripts/bootstrap.js?digest=e353d410970836974a52" />
<link rel="preload" as="script" href="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52" />

    <script data-url_root="../" id="documentation_options" src="../_static/documentation_options.js"></script>
    <script src="../_static/jquery.js"></script>
    <script src="../_static/underscore.js"></script>
    <script src="../_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="../_static/doctools.js"></script>
    <script src="../_static/clipboard.min.js"></script>
    <script src="../_static/copybutton.js"></script>
    <script src="../_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '03-optimization/03c-RSA-pytorch';</script>
    <link rel="index" title="Index" href="../genindex.html" />
    <link rel="search" title="Search" href="../search.html" />
    <link rel="next" title="Artificial neural networks" href="../04-ANNs/04a-ANNs.html" />
    <link rel="prev" title="Sheet 3.1: Gradient descent by hand" href="03b-gradient-descent.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a class="skip-link" href="#main-content">Skip to main content</a>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <nav class="bd-header navbar navbar-expand-lg bd-navbar">
    </nav>
  
  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">
  

<a class="navbar-brand logo" href="../000-intro.html">
  
  
  
  
    
    
      
    
    
    <img src="../_static/npNLG-logo.png" class="logo__image only-light" alt="Logo image"/>
    <script>document.write(`<img src="../_static/npNLG-logo.png" class="logo__image only-dark" alt="Logo image"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item"><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../000-intro.html">
                    Pragmatic Natural Language Generation with Neural Language Models
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">00 organization</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../00-organization/00a-overview.html">Course overview</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00-organization/00b-practicalities.html">Practicalities</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00-organization/00c-schedule.html">Schedule</a></li>
<li class="toctree-l1"><a class="reference internal" href="../00-organization/00d-slides.html">Slides from session 1</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">01 Probabilistic pragmatics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../01-prob-prag/01a-prob-prag.html">Probabilistic pragmatics</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01-prob-prag/01b-RSA-vanilla.html">Sheet 1.1: Vanilla RSA</a></li>
<li class="toctree-l1"><a class="reference internal" href="../01-prob-prag/01c-RSA-politeness.html">Sheet 1.2: RSA with politeness</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">02 PyTorch Basics</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../02-pytorch/02a-pytorch-basics.html">Basics of PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02-pytorch/02b-pytorch-intro.html">Sheet 2.1: PyTorch essentials</a></li>
<li class="toctree-l1"><a class="reference internal" href="../02-pytorch/02c-MLE.html">Sheet 2.2: ML-estimation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">03 Optimization</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="03a-optimization.html">Optimization in PyTorch</a></li>
<li class="toctree-l1"><a class="reference internal" href="03b-gradient-descent.html">Sheet 3.1: Gradient descent by hand</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Sheet 3.2: Optimizing an RSA model</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">04 ANNs in PyTorch</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../04-ANNs/04a-ANNs.html">Artificial neural networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../04-ANNs/04b-algebra.html">Linear algebra</a></li>
<li class="toctree-l1"><a class="reference internal" href="../04-ANNs/04c-MLP-custom.html">Sheet 4.1: Non-linear regression (custom MLP)</a></li>
<li class="toctree-l1"><a class="reference internal" href="../04-ANNs/04d-MLP-pytorch.html">Sheet 4.2: Non-linear regression (MLP w/ PyTorch modules)</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">05 RNNs in PyTorch</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../05-RNNs/05a-RNNs.html">Recurrent neural networks</a></li>
<li class="toctree-l1"><a class="reference internal" href="../05-RNNs/05b-char-level-RNN.html">Sheet 5.1: Character-level sequence modeling w/ RNNs</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">06 LSTMs in PyTorch</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../06-LSTMs/06a-LSTMs.html">Long-Short Term Memory (LSTM) models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06-LSTMs/06b-LSTM-minimal-forward-pass.html">Sheet 6.1: Anatomy of a single LSTM forward pass</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06-LSTMs/06c-char-level-LSTM.html">Sheet 6.2: Character-level sequence modeling w/ LSTMs</a></li>
<li class="toctree-l1"><a class="reference internal" href="../06-LSTMs/06d-decoding-GPT2.html">Sheet 6.3: Decoding strategies</a></li>

</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">07 Large language models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../07-LLMs/07a-LLMs.html">Large Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../07-LLMs/07b-pretrained-LLMs.html">Sheet 7.1: Using pretrained LLMs w/ the â€˜transformersâ€™ package</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">08 Grounded language models</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../08-grounded-LMs/08a-grounded-LMs.html">Grounded Language Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../08-grounded-LMs/08b-LSTM-3DShapes.html">Sheet 8.1: An LSTM-based image captioner for the annotated 3D-Shapes data set</a></li>
<li class="toctree-l1"><a class="reference internal" href="../08-grounded-LMs/08c-NIC-pretrained.html">Sheet 8.2: Using ðŸ¤—â€™s pretrained models for image captioning</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">09 neural-pragmatic NLG</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../09-np-NLG/09a-np-NLG.html">Neural pragmatic Natural Language Generation</a></li>
<li class="toctree-l1"><a class="reference internal" href="../09-np-NLG/09b-project-ideas.html">Project ideas</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://colab.research.google.com/github/michael-franke/npNLG/blob/main/neural_pragmatic_nlg/03-optimization/03c-RSA-pytorch.ipynb" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onColab"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="../_static/images/logo_colab.png">
  </span>
<span class="btn__text-container">Colab</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/michael-franke/npNLG" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/michael-franke/npNLG/issues/new?title=Issue%20on%20page%20%2F03-optimization/03c-RSA-pytorch.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="../_sources/03-optimization/03c-RSA-pytorch.ipynb" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.ipynb</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>


<script>
document.write(`
  <button class="theme-switch-button btn btn-sm btn-outline-primary navbar-btn rounded-circle" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch" data-mode="light"><i class="fa-solid fa-sun"></i></span>
    <span class="theme-switch" data-mode="dark"><i class="fa-solid fa-moon"></i></span>
    <span class="theme-switch" data-mode="auto"><i class="fa-solid fa-circle-half-stroke"></i></span>
  </button>
`);
</script>

<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Sheet 3.2: Optimizing an RSA model</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#packages">Packages</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#context-model">Context model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-empirical-data">The empirical data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-rsa-model-in-pytorch">The RSA model (in PyTorch)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parameters-to-optimize">Parameters to optimize</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization">Optimization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article" role="main">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="sheet-3-2-optimizing-an-rsa-model">
<h1>Sheet 3.2: Optimizing an RSA model<a class="headerlink" href="#sheet-3-2-optimizing-an-rsa-model" title="Permalink to this heading">#</a></h1>
<p><strong>Author:</strong> Michael Franke</p>
<p>Here we will explore how to use PyTorch to find optimized values for the parameters of a vanilla RSA model for reference games.
This serves several purposes: (i) it provides a chance to exercise with the basics of parameter optimization in PyTorch; and (ii) we learn to think about models as objects that can (and must!) be critically tested with respect to their predictive ability.</p>
<p>To fit a vanilla RSA model, we use data from <a class="reference external" href="https://michael-franke.github.io/heimseite/Papers/QingFranke_2013_Variations_on_Bayes.pdf">Qing &amp; Franke (2016)</a>. A Bayesian data analysis for this data set and model set up is provided in <a class="reference external" href="http://www.problang.org/chapters/app-04-BDA.html">this chapter of problang.org</a>.</p>
<section id="packages">
<h2>Packages<a class="headerlink" href="#packages" title="Permalink to this heading">#</a></h2>
<p>We will need to import the `torch` package for the main functionality.
In order to have a convenient handle, we load the `torch.nn.functional` package into variable `F`.
We use this to refer to the normalization function for tensors: `F.normalize`.
We use the `warnings` package to suppress all warning messages in the notebook.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>
<span class="kn">import</span> <span class="nn">torch.nn.functional</span> <span class="k">as</span> <span class="nn">F</span>
<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s1">&#39;ignore&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="context-model">
<h2>Context model<a class="headerlink" href="#context-model" title="Permalink to this heading">#</a></h2>
<p>The context model for the reference game is the same as we used before (in Sheet 1.1).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">##################################################</span>
<span class="c1">## data to fit</span>
<span class="c1">##################################################</span>

<span class="n">object_names</span>     <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;blue_circle&#39;</span><span class="p">,</span> <span class="s1">&#39;green_square&#39;</span><span class="p">,</span> <span class="s1">&#39;blue_square&#39;</span><span class="p">]</span>
<span class="n">utterance_names</span>  <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;blue&#39;</span><span class="p">,</span> <span class="s1">&#39;circle&#39;</span><span class="p">,</span> <span class="s1">&#39;green&#39;</span><span class="p">,</span> <span class="s1">&#39;square&#39;</span><span class="p">]</span>
<span class="n">semantic_meaning</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span>
    <span class="c1"># blue circle, green square, blue square</span>
    <span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">],</span>  <span class="c1"># blue</span>
     <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>  <span class="c1"># circle</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>  <span class="c1"># green</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">]],</span>  <span class="c1"># square,</span>
    <span class="n">dtype</span><span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span>
    <span class="p">)</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-empirical-data">
<h2>The empirical data<a class="headerlink" href="#the-empirical-data" title="Permalink to this heading">#</a></h2>
<p>We use empirical data from <a class="reference external" href="https://michael-franke.github.io/heimseite/Papers/QingFranke_2013_Variations_on_Bayes.pdf">Qing &amp; Franke (2016)</a>.
There were three tasks: (i) speaker production choice, and (ii) listener interpretation choice, and (iii) salience prior elicitation.
All three tasks were <em>forced-choice tasks</em>, in which participants had to select a single option from a small list of options.</p>
<p>In the speaker production task, participants were presented with the three referents.
They were told which object they should refer to.
They selected one option from the list of available utterances.</p>
<p>In the listener interpretation task, participants were presented with the three referents and an utterance.
They selected the object that they thought the speaker meant to refer to with that utterance.</p>
<p>In the salience prior elicitation task, participants again saw all three referents.
They were told that the speaker wanted to refer to one of these objects with a word in a language they did not know.
Again, they were asked to select the object they thought the speaker wanted to refer to.
Since this task rids all reasoning about semantic meaning, it is argued to represent a salience baseline of which object is a likely topic of conversation.</p>
<p>We use the data from the salience prior condition to feed into the pragmatic listener model.
The data from the speaker production and the listener interpretation tasks is our training data, i.e., what we want to explain.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">##################################################</span>
<span class="c1">## data to fit</span>
<span class="c1">##################################################</span>

<span class="n">salience_prior</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mi">71</span><span class="p">,</span><span class="mi">139</span><span class="p">,</span><span class="mi">30</span><span class="p">],</span>
                                          <span class="n">dtype</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">float32</span><span class="p">),</span>
                             <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># matrix of number of utterance choices for each state</span>
<span class="c1"># (rows: objects, columns: utterances)</span>
<span class="n">production_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">9</span><span class="p">,</span> <span class="mi">135</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                                <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">119</span><span class="p">,</span> <span class="mi">25</span><span class="p">],</span>
                                <span class="p">[</span><span class="mi">63</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">81</span><span class="p">]])</span>

<span class="c1"># matrix of number of object choices for each ambiguous utterance</span>
<span class="c1"># (rows: utterances, columns: objects)</span>
<span class="n">interpretation_data</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([[</span><span class="mi">66</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">115</span><span class="p">],</span>   <span class="c1"># &quot;blue&quot;</span>
                                    <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">117</span><span class="p">,</span> <span class="mi">62</span><span class="p">]])</span>  <span class="c1"># &quot;square&quot;</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-rsa-model-in-pytorch">
<h2>The RSA model (in PyTorch)<a class="headerlink" href="#the-rsa-model-in-pytorch" title="Permalink to this heading">#</a></h2>
<p>Here is an implementation of the vanilla RSA model in PyTorch.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">##################################################</span>
<span class="c1">## RSA model (forward pass)</span>
<span class="c1">##################################################</span>

<span class="k">def</span> <span class="nf">RSA</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">cost_adjectives</span><span class="p">):</span>
    <span class="n">costs</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">([</span><span class="mf">1.0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span> <span class="o">*</span> <span class="n">cost_adjectives</span>
    <span class="n">literal_listener</span>   <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">semantic_meaning</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">pragmatic_speaker</span>  <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="n">literal_listener</span><span class="p">)</span><span class="o">**</span><span class="n">alpha</span> <span class="o">*</span>
                                     <span class="n">torch</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">alpha</span> <span class="o">*</span> <span class="n">costs</span><span class="p">),</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">pragmatic_listener</span> <span class="o">=</span> <span class="n">F</span><span class="o">.</span><span class="n">normalize</span><span class="p">(</span><span class="n">torch</span><span class="o">.</span><span class="n">t</span><span class="p">(</span><span class="n">pragmatic_speaker</span><span class="p">)</span> <span class="o">*</span> <span class="n">salience_prior</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="mi">1</span><span class="p">,</span> <span class="n">dim</span> <span class="o">=</span> <span class="mi">1</span><span class="p">)</span>
    <span class="k">return</span><span class="p">({</span><span class="s1">&#39;speaker&#39;</span><span class="p">:</span> <span class="n">pragmatic_speaker</span><span class="p">,</span> <span class="s1">&#39;listener&#39;</span><span class="p">:</span> <span class="n">pragmatic_listener</span><span class="p">})</span>

<span class="nb">print</span><span class="p">(</span><span class="s2">&quot;speaker predictions:</span><span class="se">\n</span><span class="s2">&quot;</span><span class="p">,</span> <span class="n">RSA</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mf">1.6</span><span class="p">)[</span><span class="s1">&#39;speaker&#39;</span><span class="p">])</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>speaker predictions:
 tensor([[0.0917, 0.9083, 0.0000, 0.0000],
        [0.0000, 0.0000, 0.2876, 0.7124],
        [0.1680, 0.0000, 0.0000, 0.8320]])
</pre></div>
</div>
</div>
</div>
</section>
<section id="parameters-to-optimize">
<h2>Parameters to optimize<a class="headerlink" href="#parameters-to-optimize" title="Permalink to this heading">#</a></h2>
<p>The vanilla RSA model has two free parameters: the optimality parameter <span class="math notranslate nohighlight">\(\alpha\)</span> and the parameter for the cost of utterance, here restricted to a single number for the cost of an adjective (relative to a noun).
Since we want to optimize the value of these variables, we require PyTorch to compute gradients.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">##################################################</span>
<span class="c1">## model parameters to fit</span>
<span class="c1">##################################################</span>

<span class="n">alpha</span>           <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">1.0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># soft-max parameter</span>
<span class="n">cost_adjectives</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">tensor</span><span class="p">(</span><span class="mf">0.0</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># differential cost of &#39;adjectives&#39;</span>
</pre></div>
</div>
</div>
</div>
</section>
<section id="optimization">
<h2>Optimization<a class="headerlink" href="#optimization" title="Permalink to this heading">#</a></h2>
<p>To optimize the model parameters with stochastic gradient descent, we first instantiate an optimizer object, which we tell about the parameter to optimize.
The we iterate the training cycle, each time calling the RSA model (feed-forward pass) with the current parameter values, and then computing the (negative) log-likelihood of the data.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1">##################################################</span>
<span class="c1">## optimization</span>
<span class="c1">##################################################</span>

<span class="n">opt</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">optim</span><span class="o">.</span><span class="n">SGD</span><span class="p">([</span><span class="n">alpha</span><span class="p">,</span> <span class="n">cost_adjectives</span><span class="p">],</span> <span class="n">lr</span> <span class="o">=</span> <span class="mf">0.0001</span><span class="p">)</span>

<span class="c1"># output header</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="se">\n</span><span class="si">%5s</span><span class="s1"> </span><span class="si">%24s</span><span class="s1"> </span><span class="si">%15s</span><span class="s1"> </span><span class="si">%15s</span><span class="s1">&#39;</span> <span class="o">%</span>
      <span class="p">(</span><span class="s2">&quot;step&quot;</span><span class="p">,</span> <span class="s2">&quot;loss&quot;</span><span class="p">,</span> <span class="s2">&quot;alpha&quot;</span><span class="p">,</span> <span class="s2">&quot;cost&quot;</span><span class="p">)</span> <span class="p">)</span>

<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">4000</span><span class="p">):</span>

    <span class="n">RSA_prediction</span>      <span class="o">=</span> <span class="n">RSA</span><span class="p">(</span><span class="n">alpha</span><span class="p">,</span> <span class="n">cost_adjectives</span><span class="p">)</span>
    <span class="n">speaker_pred</span>        <span class="o">=</span> <span class="n">RSA_prediction</span><span class="p">[</span><span class="s1">&#39;speaker&#39;</span><span class="p">]</span>
    <span class="n">Multinomial_speaker</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">multinomial</span><span class="o">.</span><span class="n">Multinomial</span><span class="p">(</span><span class="mi">144</span><span class="p">,</span> <span class="n">probs</span> <span class="o">=</span> <span class="n">speaker_pred</span><span class="p">)</span>
    <span class="n">logProbs_speaker</span>    <span class="o">=</span> <span class="n">Multinomial_speaker</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">production_data</span><span class="p">)</span>

    <span class="n">listener_pred</span>          <span class="o">=</span> <span class="n">RSA_prediction</span><span class="p">[</span><span class="s1">&#39;listener&#39;</span><span class="p">]</span>
    <span class="n">Multinomial_listener_0</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">multinomial</span><span class="o">.</span><span class="n">Multinomial</span><span class="p">(</span><span class="mi">181</span><span class="p">,</span><span class="n">probs</span> <span class="o">=</span> <span class="n">listener_pred</span><span class="p">[</span><span class="mi">0</span><span class="p">,])</span>
    <span class="n">logProbs_listener_0</span>    <span class="o">=</span> <span class="n">Multinomial_listener_0</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">interpretation_data</span><span class="p">[</span><span class="mi">0</span><span class="p">,])</span>
    <span class="n">Multinomial_listener_1</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">distributions</span><span class="o">.</span><span class="n">multinomial</span><span class="o">.</span><span class="n">Multinomial</span><span class="p">(</span><span class="mi">179</span><span class="p">,</span><span class="n">probs</span> <span class="o">=</span> <span class="n">listener_pred</span><span class="p">[</span><span class="mi">3</span><span class="p">,])</span>
    <span class="n">logProbs_listener_1</span>    <span class="o">=</span> <span class="n">Multinomial_listener_1</span><span class="o">.</span><span class="n">log_prob</span><span class="p">(</span><span class="n">interpretation_data</span><span class="p">[</span><span class="mi">1</span><span class="p">,])</span>

    <span class="n">loss</span> <span class="o">=</span> <span class="o">-</span><span class="n">torch</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">logProbs_speaker</span><span class="p">)</span> <span class="o">-</span> <span class="n">logProbs_listener_0</span> <span class="o">-</span> <span class="n">logProbs_listener_1</span>

    <span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>

    <span class="k">if</span> <span class="p">(</span><span class="n">i</span><span class="o">+</span><span class="mi">1</span><span class="p">)</span> <span class="o">%</span> <span class="mi">250</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="nb">print</span><span class="p">(</span><span class="s1">&#39;</span><span class="si">%5d</span><span class="s1"> </span><span class="si">%24.5f</span><span class="s1"> </span><span class="si">%15.5f</span><span class="s1"> </span><span class="si">%15.5f</span><span class="s1">&#39;</span> <span class="o">%</span>
              <span class="p">(</span><span class="n">i</span> <span class="o">+</span> <span class="mi">1</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">alpha</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span>
               <span class="n">cost_adjectives</span><span class="o">.</span><span class="n">item</span><span class="p">())</span> <span class="p">)</span>

    <span class="n">opt</span><span class="o">.</span><span class="n">step</span><span class="p">()</span>
    <span class="n">opt</span><span class="o">.</span><span class="n">zero_grad</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>#+begin_example

 step                     loss           alpha            cost
  250                 21.74205         2.12154         0.17193
  500                 16.10578         2.47786         0.15869
  750                 15.55774         2.58906         0.15650
 1000                 15.50400         2.62389         0.15597
 1250                 15.49873         2.63481         0.15582
 1500                 15.49818         2.63825         0.15577
 1750                 15.49814         2.63933         0.15576
 2000                 15.49815         2.63966         0.15575
 2250                 15.49813         2.63977         0.15575
 2500                 15.49815         2.63979         0.15575
 2750                 15.49815         2.63979         0.15575
 3000                 15.49815         2.63979         0.15575
 3250                 15.49815         2.63979         0.15575
 3500                 15.49815         2.63979         0.15575
 3750                 15.49815         2.63979         0.15575
 4000                 15.49815         2.63979         0.15575
#+end_example
</pre></div>
</div>
</div>
</div>
<blockquote>
<div><p><strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 2.3.1: Comparing model variants </span></strong></p>
<ol class="arabic simple">
<li><p>We have so far implemented the literal listener as <span class="math notranslate nohighlight">\(P_{lit}(s \mid u) \propto L_{ij}\)</span>. But some RSA models also include the salience prior, which we have so far only used in the pragmatic listener part into the literal listener model. Under this alternative construction the literal listener would be defined as <span class="math notranslate nohighlight">\(P_{lit}(s \mid u) \propto P_{sal}(s) \ L_{ij}\)</span>. Change the `RSA` function to implement this alternative definition. (Hint: you only need to add this string somewhere in the code: `* salience<sub>prior</sub>`.) Run the model otherwise as is. Inspect the output of the optimization loop. Use this information to draw conclusions about which of the two model variants is a better predictor of the data.</p></li>
<li><p>Go back to the original model. We now want to address whether we actually need the cost parameter. Run the original model (w/ a literal listener w/o salience prior information), but optimize only the <span class="math notranslate nohighlight">\(\alpha\)</span> parameter. The cost parameter should be initialized to 0 and stay this way. Fit the model and use the output information to draw conclusions about which model is better: with or without a flexible cost parameter.</p></li>
</ol>
</div></blockquote>
</section>
<section id="references">
<h2>References<a class="headerlink" href="#references" title="Permalink to this heading">#</a></h2>
<p>Qing, C., &amp; Franke, M. (2015). <a class="reference external" href="https://michael-franke.github.io/heimseite/Papers/QingFranke_2013_Variations_on_Bayes.pdf">Variations on a Bayesian theme: Comparing Bayesian models of referential reasoning</a>. In H. Zeevat, &amp; H. Schmitz (Eds.), Bayesian Natural Language Semantics and Pragmatics (pp. 201â€“220). Berlin: Springer.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./03-optimization"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
                <footer class="bd-footer-article">
                  
<div class="footer-article-items footer-article__inner">
  
    <div class="footer-article-item"><!-- Previous / next buttons -->
<div class="prev-next-area">
    <a class="left-prev"
       href="03b-gradient-descent.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Sheet 3.1: Gradient descent by hand</p>
      </div>
    </a>
    <a class="right-next"
       href="../04-ANNs/04a-ANNs.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Artificial neural networks</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div></div>
  
</div>

                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">

  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#packages">Packages</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#context-model">Context model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-empirical-data">The empirical data</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-rsa-model-in-pytorch">The RSA model (in PyTorch)</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#parameters-to-optimize">Parameters to optimize</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#optimization">Optimization</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#references">References</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Michael Franke
</p>

  </div>
  
  <div class="footer-item">
    
  <p class="copyright">
    
      Â© Copyright 2022.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../_static/scripts/bootstrap.js?digest=e353d410970836974a52"></script>
<script src="../_static/scripts/pydata-sphinx-theme.js?digest=e353d410970836974a52"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>