#+title:     Sheet 2.2: ML-estimation
#+author:    Michael Franke

This tutorial is meant to introduce some basics of PyTorch by looking at a simple case study: how to find the best-fitting parameter for the mean of a normal (Gaussian) distribution.
The training data is a set of samples from a "true" distribution.
The loss function is the negative likelihood that a candidate parameter value for the "true mean" assigns to the training data.
By using stochastic gradient descent to minimize the loss, we seek the parameter value that maximizes the likelihood of the training data.
This is, therefore, a *maximum likelihood estimation*.

* Packages

We will need to import the `torch` package for the main functionality.
We also will use `seaborn` for plotting, and `matplotlib` for showing the plots.
Finally, we use the `warnings` package to suppress all warning messages in the notebook.

#+begin_src jupyter-python
import torch
import seaborn as sns
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
#+end_src

#+RESULTS:

* True distribution & training data

The "true distribution" that generates the data is a normal distribution with a mean (location) stored in the variable `trueLocation`.
(We keep the scale parameter (standard deviation) fixed at a known value of 1.)
The `torch.distributions` package contains ready-made probability distributions for sampling.
So, here we define the true distribution, and take `nObs` samples from it, the set of which we call "training data".

#+begin_src jupyter-python
nObs           = 10000
trueLocation   = 0 # mean of a normal
trueDist       = torch.distributions.Normal(loc=trueLocation, scale=1.0)
trainData      = trueDist.sample([nObs])
print(trainData)
#+end_src

#+RESULTS:
: tensor([-2.7541, -0.1136, -0.6435,  ..., -0.1871, -0.3822, -0.1319])

The mean of the training data is the so-called *empirical mean*.
The empirical mean need not be identical to the true mean!

#+begin_src jupyter-python
empirical_mean = torch.mean(trainData)
print('Empirical mean (mean of training data): %.5f' % empirical_mean.item())
#+end_src

#+RESULTS:
: Empirical mean (mean of training data): -0.01449

Here is a density plot of the training data:

#+begin_src jupyter-python
sns.kdeplot(trainData)
plt.show()
#+end_src

#+RESULTS:
[[file:./.ob-jupyter/9b062ed691956b5ca43c5f8924b33e5330f1980c.png]]

* Optimizing a parameter: gradients, optimizers, loss & backprop

We want an estimate of the true mean of the training data.
For that, we define a "trainable" parameter in PyTorch, which we set to some initial value.
Subsequently, we will update the value of this parameter in a series of training steps, so that it will become "better" over time.
Being "good" means having a small "loss".
The loss function we are interested in is the likelihood of the training data.

To being with, we define the parameter which is to be trained.
Since we want to "massage it" through updating, we must tell PyTorch that it should compute the gradient for this parameter (and the ones derived from it).

#+begin_src jupyter-python
location = torch.tensor(1.0, requires_grad=True) # random initial starting point
print( location )
#+end_src

#+RESULTS:
: tensor(1., requires_grad=True)

To prepare for training, we first instantiate an *optimizer*, which will do the updating behind the scenes.
Here, we choose the stochastic gradient descent (SGD) optimizer.
To instantiate it, we need to tell it two things:

1. which parameters to optimize;
2. how aggressively to update (=> the so-called *learning rate*)

#+begin_src jupyter-python
learningRate = 0.0000001
opt          = torch.optim.SGD([location], lr=learningRate)
#+end_src

#+RESULTS:

Let us now go manually through a single training step.
A training step consists of the following parts:

1. compute the predictions for the current parameter(s)
   - what do we predict in the current state?
2. compute the loss for this prediction
   - how good is this prediction (for the training data)?
3. backpropagate the error (using the gradients)
   - in which direction would we need to change the relevant parameters to make the prediction better?
4. update step
   - change the parameters (to a certain degree, the so-called learning rate) in the direction that should make them better
5. zero the gradient
   - reset the information about "which direction to tune" for the next training step

** Part 1: Compute the predictions for current parameter value

The prediction for the current parameter value is a Gaussian with the location parameter set to our current parameter value.
We obtain our "current best model" by instantiating a distribution like so:

#+begin_src jupyter-python
prediction = torch.distributions.Normal(loc=location, scale=1.0)
#+end_src

#+RESULTS:

** Part 2: Computing the loss for the current prediction

How good is our current model?
Goodness can be measured in many ways.
Here we consider the likelihood: how likely is the training data under the current model?

#+begin_src jupyter-python
loss     = -torch.sum(prediction.log_prob(trainData))
print(loss)
#+end_src

#+RESULTS:
: tensor([-1.6429, -2.2677, -0.9448,  ..., -1.3587, -0.9517, -0.9194],
:        grad_fn=<SubBackward0>)

Notice that the `loss` variable is a single-numbered tensor (containing the information how bad (we want to minimize it) the current parameter value is).
Notice that PyTorch has also added information on how to compute gradients, i.e., it keeps track of way in which values for the variable `location` influence the values for the variable `loss`.

** Part 3: Backpropagate the error signal

In the next step, we will use the information stored about the functional relation between `location` and `loss` to infer how the `location` parameter would need to be changed to make `loss` higher or lower.
This is the so-called backpropagation step.

Concretely, at the outset, the gradient information for `location` is "NONE".

#+begin_src jupyter-python
print(f"Value (initial)                = { location.item()}")
print(f"Gradient information (initial) = { location.grad}")
#+end_src

#+RESULTS:
: Value (initial)                = 1.0
: Gradient information (initial) = None

We must actively tell the system to backpropagate the information in the gradients, like so:

#+begin_src jupyter-python
loss.backward()
print(f"Value (after backprop)                = { location.item()}")
print(f"Gradient information (after backprop) = { location.grad}")
#+end_src

#+RESULTS:
: Value (after backprop)                = 1.0
: Gradient information (after backprop) = 9800.26171875

** Part 4: Update the parameter values

Next, we use the information in the gradient to actually update the trainable parameter values.
This is what the optimizer does.
It knows which parameters to update (we told it), so the relevant update function is one associated with the optimizer itself.

#+begin_src jupyter-python
opt.step()
print(f"Value (after step)                = { location.item()}")
print(f"Gradient information (after step) = { location.grad}")
#+end_src

#+RESULTS:
: Value (after step)                = 0.999019980430603
: Gradient information (after step) = 9800.26171875

** Part 5: Reset the gradient information

If we want to repeat the updating process, we need to erase information about gradients for the last prediction.
This is because otherwise information would just accumulate in the gradients.
This zero-ing of the gradients is again something we do holistically (for all parameters to train) through the optimizer object:

#+begin_src jupyter-python
opt.zero_grad()
print(f"Value (after zero-ing)                = { location.item()}")
print(f"Gradient information (after zero-ing) = { location.grad}")
#+end_src

#+RESULTS:
: Value (after zero-ing)                = 0.999019980430603
: Gradient information (after zero-ing) = 0.0

* Training loop

After having gone through our cycle of parameter updating step-by-step, let's iterate this in a training loop consisting of `nTrainingSteps`.

#+begin_src jupyter-python
nTrainingSteps= 10000
print('\n%5s %24s %15s %15s' %
      ("step", "loss", "estimate", "diff. target") )
for i in range(nTrainingSteps):
    prediction = torch.distributions.Normal(loc=location, scale=1.0)
    loss = -torch.sum(prediction.log_prob(trainData))
    loss.backward()
    if (i+1) % 500 == 0:
        print('%5d %24.3f %15.5f %15.5f' %
              (i + 1, loss.item(), location.item(),
               abs(location.item() - empirical_mean) ) )
    opt.step()
    opt.zero_grad()
#+end_src

#+RESULTS:
#+begin_example

 step                     loss        estimate    diff. target
  500                16103.394         0.60129         0.61578
 1000                14904.594         0.35891         0.37339
 1500                14463.803         0.21193         0.22642
 2000                14301.727         0.12281         0.13730
 2500                14242.131         0.06877         0.08325
 3000                14220.219         0.03600         0.05048
 3500                14212.161         0.01613         0.03061
 4000                14209.197         0.00408         0.01856
 4500                14208.109        -0.00323         0.01126
 5000                14207.709        -0.00766         0.00683
 5500                14207.562        -0.01035         0.00414
 6000                14207.507        -0.01198         0.00251
 6500                14207.487        -0.01296         0.00152
 7000                14207.480        -0.01356         0.00092
 7500                14207.478        -0.01393         0.00056
 8000                14207.477        -0.01415         0.00034
 8500                14207.477        -0.01428         0.00021
 9000                14207.476        -0.01436         0.00012
 9500                14207.477        -0.01441         0.00008
10000                14207.477        -0.01444         0.00005
#+end_example



> <strong><span style="color:#D83D2B;">Exercise 2.2.1: Explore the optimization process</span></strong>
> 1. Change the true mean (parameter `trueLocation`) to 10e6. Is training still successful?  What would you change?
> 2. Revert to initial conditions. Change the initial value of the parameter `location` to -5000. Does training work? What's the problem? How would you fix it?
> 3. Revert to initial conditions. Rerun the script with only 100 samples (using variable `nObs`). Does the training work? What's the problem? How would you fix it?


