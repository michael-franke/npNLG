{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sheet 6.2: Character-level sequence modeling w/ LSTMs\n",
    "=====================================================\n",
    "\n",
    "**Author:** Michael Franke\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial builds on the earlier tutorial (5.1) where we implemented a character-level RNN.\n",
    "Previously we implemented the RNN model without making use of PyTorch&rsquo;s built-in functions.\n",
    "In this tutorial, we will implement an LSTM using these convenient functions.\n",
    "Applying the new LSTM model to the exact same data (surname predictions for different countries), we can compare the efficiency and power of the two architectures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages & global parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imports as before in (5.1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "## import packages\n",
    "##################################################\n",
    "\n",
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import json\n",
    "import glob\n",
    "import os\n",
    "import unicodedata\n",
    "import pandas\n",
    "import string\n",
    "import torch\n",
    "import urllib.request\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import time\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load & pre-process data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "## read and inspect the data\n",
    "##################################################\n",
    "# with urllib.request.urlopen(\"https://raw.githubusercontent.com/michael-franke/npNLG/main/neural_pragmatic_nlg/05-RNNs/names-data.json\") as url:\n",
    "#     namesData = json.load(url)\n",
    "\n",
    "with open('names-data.json') as dataFile:\n",
    "    namesData = json.load(dataFile)\n",
    "\n",
    "categories = list(namesData.keys())\n",
    "n_categories   = len(categories)\n",
    "\n",
    "# we use all ASCII letters as the vocabulary (plus tokens [EOS], [SOS])\n",
    "all_letters = string.ascii_letters + \" .,;'-\"\n",
    "n_letters   = len(all_letters) + 2 # all letter plus [EOS] and [SOS] token\n",
    "SOSIndex    = n_letters - 1\n",
    "EOSIndex    = n_letters - 2\n",
    "\n",
    "##################################################\n",
    "## make a train/test split\n",
    "##################################################\n",
    "\n",
    "train_data = dict()\n",
    "test_data  = dict()\n",
    "split_percentage = 10\n",
    "for k in list(namesData.keys()):\n",
    "    total_size    = len(namesData[k])\n",
    "    test_size     = round(total_size/split_percentage)\n",
    "    train_size    = total_size - test_size\n",
    "    print(k, total_size, train_size, test_size)\n",
    "    indices       = [i for i in range(total_size)]\n",
    "    random.shuffle(indices)\n",
    "    train_indices = indices[0:train_size]\n",
    "    test_indices  = indices[(train_size+1):(-1)]\n",
    "    train_data[k] = [namesData[k][i] for i in train_indices]\n",
    "    test_data[k]  = [namesData[k][i] for i in test_indices]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define LSTM module\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "## define LSTM\n",
    "##################################################\n",
    "\n",
    "class LSTM(nn.Module):\n",
    "    def __init__(self, cat_embedding_size, n_cat,\n",
    "                 char_embedding_size, n_char,\n",
    "                 hidden_size, output_size, num_layers = 2, dropout = 0.1):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        # category embedding\n",
    "        self.cat_embedding = nn.Embedding(n_cat, cat_embedding_size)\n",
    "        # character embedding\n",
    "        self.char_embedding = nn.Embedding(n_char, char_embedding_size)\n",
    "        # the actual LSTM\n",
    "        self.lstm = nn.LSTM(input_size  = cat_embedding_size+char_embedding_size,\n",
    "                            hidden_size = hidden_size,\n",
    "                            num_layers  = num_layers,\n",
    "                            batch_first = True,\n",
    "                            dropout = dropout\n",
    "                            )\n",
    "        # linear map onto weights for words\n",
    "        self.linear_map = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, category, name, hidden):\n",
    "        cat_emb  = self.cat_embedding(category)\n",
    "        char_emb = self.char_embedding(name)\n",
    "        # print(cat_emb)\n",
    "        # print(char_emb)\n",
    "        # print(\"concat input:\", torch.concat([cat_emb, char_emb], dim = 1))\n",
    "        output, (hidden, cell) = self.lstm(torch.concat([cat_emb, char_emb], dim = 1))\n",
    "        # print(\"output:\", output)\n",
    "        predictions = self.linear_map(output)\n",
    "        # print(\"predictions:\", torch.nn.functional.log_softmax(predictions))\n",
    "        # print(next_word_probabilities(predictions))\n",
    "        return torch.nn.functional.log_softmax(predictions, dim = 1), hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)\n",
    "\n",
    "# # get probabilities from output logits\n",
    "# def next_word_probabilities(logits):\n",
    "#     softmax = torch.nn.Softmax(dim=2)\n",
    "#     return(softmax(logits).detach().numpy().round(4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions for training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "## helper functions for training\n",
    "##################################################\n",
    "\n",
    "# Random item from a list\n",
    "def randomChoice(l):\n",
    "    return l[random.randint(0, len(l) - 1)]\n",
    "\n",
    "# Get a random category and random line from that category\n",
    "def randomTrainingPair():\n",
    "    category = randomChoice(categories)\n",
    "    name = randomChoice(train_data[category])\n",
    "    # category = categories[random.randint(0, len(categories) - 1)]\n",
    "    return category, name\n",
    "\n",
    "def getNameIndices(name):\n",
    "    indices = [SOSIndex] + [all_letters.index(c) for c in list(name)] + [EOSIndex]\n",
    "    return indices\n",
    "\n",
    "def getCatIndices(category, name_length):\n",
    "    return torch.full((1,name_length), categories.index(category)).reshape(-1)\n",
    "\n",
    "def randomTrainingExample():\n",
    "    category, name = randomTrainingPair()\n",
    "    name_length = len(name) + 2\n",
    "    return getCatIndices(category, name_length), torch.tensor(getNameIndices(name))\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single training step\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "## single training pass\n",
    "##################################################\n",
    "\n",
    "def train(cat, name):\n",
    "    # get a fresh hidden layer\n",
    "    hidden = lstm.initHidden()\n",
    "    # zero the gradients\n",
    "    optimizer.zero_grad()\n",
    "    # run sequence\n",
    "    predictions, hidden = lstm(cat, name, hidden)\n",
    "    # compute loss (NLLH)\n",
    "    loss = criterion(predictions[:-1], name[1:len(name)])\n",
    "    # perform backward pass\n",
    "    loss.backward()\n",
    "    # perform optimization\n",
    "    optimizer.step()\n",
    "    # return prediction and loss\n",
    "    return loss.item() # / input_line_tensor.size(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model instantiation & training loop\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "## actual training loop\n",
    "## (should take about 2-4 minutes)\n",
    "##################################################\n",
    "\n",
    "# instantiate model\n",
    "lstm = LSTM(cat_embedding_size  = 32,\n",
    "            n_cat               = n_categories,\n",
    "            char_embedding_size = 32,\n",
    "            n_char              = n_letters,\n",
    "            hidden_size         = 64,\n",
    "            output_size         = n_letters,\n",
    "            dropout             = 0.1,\n",
    "            num_layers          = 1\n",
    "            )\n",
    "# training objective\n",
    "criterion = nn.NLLLoss(reduction='sum')\n",
    "# learning rate\n",
    "learning_rate = 0.005\n",
    "# optimizer\n",
    "optimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n",
    "# training parameters\n",
    "n_iters = 50000\n",
    "print_every = 5000\n",
    "plot_every = 500\n",
    "all_losses = []\n",
    "total_loss = 0 # will be reset every 'plot_every' iterations\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "for iter in range(1, n_iters + 1):\n",
    "    loss = train(*randomTrainingExample())\n",
    "    total_loss += loss\n",
    "\n",
    "    if iter % plot_every == 0:\n",
    "        all_losses.append(total_loss / plot_every)\n",
    "        total_loss = 0\n",
    "\n",
    "    if iter % print_every == 0:\n",
    "        rolling_mean = np.mean(all_losses[iter - print_every*(iter//print_every):])\n",
    "        print('%s (%d %d%%) %.4f' % (timeSince(start),\n",
    "                                     iter,\n",
    "                                     iter / n_iters * 100,\n",
    "                                     rolling_mean))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plotting training performance\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "## monitoring loss function during training\n",
    "##################################################\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(all_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "## evaluation\n",
    "##################################################\n",
    "\n",
    "def get_surprisal_item(category, name):\n",
    "    name      = torch.tensor(getNameIndices(name))\n",
    "    cat       = getCatIndices(category,len(name))\n",
    "    hidden    = lstm.initHidden()\n",
    "    prediction, hidden = lstm(cat, name, hidden)\n",
    "    nll       = criterion(prediction[:-1], name[1:len(name)])\n",
    "    return(nll.item())\n",
    "\n",
    "def get_surprisal_dataset(data):\n",
    "    surprisl_dict = dict()\n",
    "    surp_avg_dict = dict()\n",
    "    perplxty_dict = dict()\n",
    "    for category in list(data.keys()):\n",
    "        surprisl = 0\n",
    "        surp_avg = 0\n",
    "        perplxty = 0\n",
    "        # training\n",
    "        for name in data[category]:\n",
    "            item_surpr = get_surprisal_item(category, name)\n",
    "            surprisl  += item_surpr\n",
    "            surp_avg  += item_surpr / len(name)\n",
    "            perplxty  += item_surpr ** (-1 / len(name))\n",
    "        n_items = len(data[category])\n",
    "\n",
    "        surprisl_dict[category] = (surprisl /n_items)\n",
    "        surp_avg_dict[category] = (surp_avg / n_items)\n",
    "        perplxty_dict[category] = (perplxty / n_items)\n",
    "\n",
    "    return(surprisl_dict, surp_avg_dict, perplxty_dict)\n",
    "\n",
    "def makeDF(surp_dict):\n",
    "    p = pandas.DataFrame.from_dict(surp_dict)\n",
    "    p = p.transpose()\n",
    "    p.columns = [\"surprisal\", \"surp_scaled\", \"perplexity\"]\n",
    "    return(p)\n",
    "\n",
    "surprisal_test  = makeDF(get_surprisal_dataset(test_data))\n",
    "surprisal_train = makeDF(get_surprisal_dataset(train_data))\n",
    "\n",
    "print(\"\\nmean surprisal (test):\", np.mean(surprisal_test[\"surprisal\"]))\n",
    "print(\"\\nmean surprisal (train):\", np.mean(surprisal_train[\"surprisal\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring model predictions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "## prediction function\n",
    "##################################################\n",
    "\n",
    "max_length = 20\n",
    "\n",
    "# make a prediction based on given sequence\n",
    "def predict(category, initial_sequence, decode_strat = \"greedy\"):\n",
    "\n",
    "    if len(initial_sequence) >= max_length:\n",
    "        return(initial_sequence)\n",
    "\n",
    "    name      = torch.tensor(getNameIndices(initial_sequence))[:-1]\n",
    "    cat       = getCatIndices(category,len(name))\n",
    "    hidden    = lstm.initHidden()\n",
    "\n",
    "    generation = initial_sequence\n",
    "\n",
    "    output, hidden = lstm(cat, name, hidden)\n",
    "    next_word_pred = output[-1]\n",
    "\n",
    "    if decode_strat == \"pure\":\n",
    "        sample_index = torch.multinomial(input = torch.exp(next_word_pred),\n",
    "                                         num_samples = 1)\n",
    "        pass\n",
    "    else:\n",
    "        topv, topi = next_word_pred.topk(1)\n",
    "        sample_index = topi[0].item()\n",
    "\n",
    "    if sample_index == EOSIndex:\n",
    "        return(generation)\n",
    "    else:\n",
    "        generation += all_letters[sample_index]\n",
    "\n",
    "    return(predict(category, generation))\n",
    "\n",
    "print(predict(\"German\", \"\", decode_strat = \"greedy\"))\n",
    "print(predict(\"German\", \"\", decode_strat = \"pure\"))\n",
    "print(predict(\"German\", \"\", decode_strat = \"pure\"))\n",
    "print(predict(\"German\", \"\", decode_strat = \"pure\"))\n",
    "\n",
    "print(predict(\"Japanese\", \"\", decode_strat = \"greedy\"))\n",
    "print(predict(\"Japanese\", \"\", decode_strat = \"pure\"))\n",
    "print(predict(\"Japanese\", \"\", decode_strat = \"pure\"))\n",
    "print(predict(\"Japanese\", \"\", decode_strat = \"pure\"))\n",
    "\n",
    "# extend the 'predict' function to include a parameter to implement the following decoding schemes:\n",
    "# - top-k (variable k)\n",
    "# - softmax (variable soft-max parameter)\n",
    "# - top-p (variable p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Class predictions from the generation model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def infer_category(name):\n",
    "    probs = torch.tensor([torch.exp(-torch.tensor(get_surprisal_item(c, name))) for c in categories])\n",
    "    probs = probs/torch.sum(probs)\n",
    "    vals, cats = probs.topk(3)\n",
    "    print(\"Top 3 guesses for \", name, \":\\n\")\n",
    "    for i in range(len(cats)):\n",
    "        print(\"%12s: %.5f\" %\n",
    "              (categories[cats[i]], vals[i].detach().numpy() ))\n",
    "\n",
    "# that's really interesting: there is a base-rate effect!\n",
    "infer_category(\"Smith\")\n",
    "infer_category(\"Miller\")\n",
    "\n",
    "# Bonus exercise:\n",
    "# what's going on here?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
