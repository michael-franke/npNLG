{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": "Sheet 6.2: Character-level sequence modeling w/ LSTMs\n=====================================================\n\n**Author:** Michael Franke\n\n"
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "This tutorial builds on the earlier tutorial (5.1) which implemented a character-level RNN.\nPreviously we implemented the RNN model without making use of PyTorch&rsquo;s built-in functions.\nIn this tutorial, we will implement an LSTM using these convenient functions.\nApplying the new LSTM model to the exact same data (surname predictions for different countries), we can compare the efficiency and power of the two architectures.\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "## Packages & global parameters\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "Imports as before in (5.1).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [],
      "source": [
        "##################################################\n## import packages\n##################################################\n\nfrom __future__ import unicode_literals, print_function, division\nfrom io import open\nimport json\nimport glob\nimport os\nimport unicodedata\nimport pandas\nimport string\nimport torch\nimport urllib.request\nimport numpy as np\nimport torch.nn as nn\nimport random\nimport time\nimport math\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings('ignore')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "## Load & pre-process data\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "Loading and pre-processing the data is also as before in sheet 5.1.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "#+begin_example\nCzech 519 467 52\nGerman 724 652 72\nArabic 2000 1800 200\nJapanese 991 892 99\nChinese 268 241 27\nVietnamese 73 66 7\nRussian 9408 8467 941\nFrench 277 249 28\nIrish 232 209 23\nEnglish 3668 3301 367\nSpanish 298 268 30\nGreek 203 183 20\nItalian 709 638 71\nPortuguese 74 67 7\nScottish 100 90 10\nDutch 297 267 30\nKorean 94 85 9\nPolish 139 125 14\n#+end_example"
        }
      ],
      "source": [
        "##################################################\n## read and inspect the data\n##################################################\n# with urllib.request.urlopen(\"https://raw.githubusercontent.com/michael-franke/npNLG/main/neural_pragmatic_nlg/05-RNNs/names-data.json\") as url:\n#     namesData = json.load(url)\n\n# with open('names-data.json') as dataFile:\n#     namesData = json.load(dataFile)\n\ncategories = list(namesData.keys())\nn_categories   = len(categories)\n\n# we use all ASCII letters as the vocabulary (plus tokens [EOS], [SOS])\nall_letters = string.ascii_letters + \" .,;'-\"\nn_letters   = len(all_letters) + 2 # all letter plus [EOS] and [SOS] token\nSOSIndex    = n_letters - 1\nEOSIndex    = n_letters - 2\n\n##################################################\n## make a train/test split\n##################################################\n\ntrain_data = dict()\ntest_data  = dict()\nsplit_percentage = 10\nfor k in list(namesData.keys()):\n    total_size    = len(namesData[k])\n    test_size     = round(total_size/split_percentage)\n    train_size    = total_size - test_size\n    # print(k, total_size, train_size, test_size)\n    indices       = [i for i in range(total_size)]\n    random.shuffle(indices)\n    train_indices = indices[0:train_size]\n    test_indices  = indices[(train_size+1):(-1)]\n    train_data[k] = [namesData[k][i] for i in train_indices]\n    test_data[k]  = [namesData[k][i] for i in test_indices]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "## Define LSTM module\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "The definition of the LSTM model follows the steps explained in the previous worksheet (6.1) closely.\nNB: we include a dropout rate (which here acts in between layers of the stacked LSTM).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [],
      "source": [
        "##################################################\n## define LSTM\n##################################################\n\nclass LSTM(nn.Module):\n    def __init__(self, cat_embedding_size, n_cat,\n                 char_embedding_size, n_char,\n                 hidden_size, output_size, num_layers = 2, dropout = 0.1):\n        super(LSTM, self).__init__()\n        self.hidden_size = hidden_size\n        # category embedding\n        self.cat_embedding = nn.Embedding(n_cat, cat_embedding_size)\n        # character embedding\n        self.char_embedding = nn.Embedding(n_char, char_embedding_size)\n        # the actual LSTM\n        self.lstm = nn.LSTM(input_size  = cat_embedding_size+char_embedding_size,\n                            hidden_size = hidden_size,\n                            num_layers  = num_layers,\n                            batch_first = True,\n                            dropout = dropout\n                            )\n        # linear map onto weights for words\n        self.linear_map = nn.Linear(hidden_size, output_size)\n\n    def forward(self, category, name, hidden):\n        cat_emb  = self.cat_embedding(category)\n        char_emb = self.char_embedding(name)\n        output, (hidden, cell) = self.lstm(torch.concat([cat_emb, char_emb], dim = 1))\n        predictions = self.linear_map(output)\n        return torch.nn.functional.log_softmax(predictions, dim = 1), hidden\n\n    def initHidden(self):\n        return torch.zeros(1, self.hidden_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 6.2.1: </span></strong>\n>\n> 1. How is the category information supplied to next network? I.e.,, what is the input format and how is this information made accessible for computation at every word?\n>\n> 2. What exactly is the return value of a single forward pass?\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "## Helper functions for training\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "Again, the following training functions are similar to what we used in sheet 5.1, but changed to handle the different representational format of the input.\n(Previous work sheet used a one-hot vector representation where we here use an index (integer) representation for each word.)\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [],
      "source": [
        "##################################################\n## helper functions for training\n##################################################\n\n# Random item from a list\ndef randomChoice(l):\n    return l[random.randint(0, len(l) - 1)]\n\n# Get a random category and random name from that category\ndef randomTrainingPair():\n    category = randomChoice(categories)\n    name = randomChoice(train_data[category])\n    return category, name\n\n# get index representation of name (in the proper format)\ndef getNameIndices(name):\n    indices = [SOSIndex] + [all_letters.index(c) for c in list(name)] + [EOSIndex]\n    return indices\n\n# get index representation of category (in the proper format)\n# NB: must have same length as corresponding name representation b/c\n#     each character in the sequence is concatenated with the category information\ndef getCatIndices(category, name_length):\n    return torch.full((1,name_length), categories.index(category)).reshape(-1)\n\n# get random training pair in desired input format (vectors of indices)\ndef randomTrainingExample():\n    category, name = randomTrainingPair()\n    name_length = len(name) + 2\n    return getCatIndices(category, name_length), torch.tensor(getNameIndices(name))\n\ndef timeSince(since):\n    now = time.time()\n    s = now - since\n    m = math.floor(s / 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "## Single training step\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "A single training loop for a single pair of category and name considers the output predictions of the LSTM.\nThe way we defined the LSTM above makes it so that the first component that is returned feeds directly in to the loss function (negative log likeihood).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [],
      "source": [
        "##################################################\n## single training pass\n##################################################\n\ndef train(cat, name):\n    # get a fresh hidden layer\n    hidden = lstm.initHidden()\n    # zero the gradients\n    optimizer.zero_grad()\n    # run sequence\n    predictions, hidden = lstm(cat, name, hidden)\n    # compute loss (NLLH)\n    loss = criterion(predictions[:-1], name[1:len(name)])\n    # perform backward pass\n    loss.backward()\n    # perform optimization\n    optimizer.step()\n    # return prediction and loss\n    return loss.item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "## Model instantiation & training loop\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "The LSTM we instantiate here is rather smallish.\nIt has only one layer, a hidden and cell state of size 64 and uses an embedding size of 32 for both categories and names.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": "#+begin_example\n0m 6s (5000 10%) 16.7143\n0m 12s (10000 20%) 15.9386\n0m 18s (15000 30%) 15.4798\n0m 24s (20000 40%) 15.1522\n0m 30s (25000 50%) 14.9384\n0m 36s (30000 60%) 14.7415\n0m 42s (35000 70%) 14.5792\n0m 48s (40000 80%) 14.4516\n0m 54s (45000 90%) 14.3326\n1m 0s (50000 100%) 14.2348\n#+end_example"
        }
      ],
      "source": [
        "##################################################\n## actual training loop\n## (should take about 1-2 minutes)\n##################################################\n\n# instantiate model\nlstm = LSTM(cat_embedding_size  = 32,\n            n_cat               = n_categories,\n            char_embedding_size = 32,\n            n_char              = n_letters,\n            hidden_size         = 64,\n            output_size         = n_letters,\n            dropout             = 0,\n            num_layers          = 1\n            )\n# training objective\ncriterion = nn.NLLLoss(reduction='sum')\n# learning rate\nlearning_rate = 0.005\n# optimizer\noptimizer = torch.optim.Adam(lstm.parameters(), lr=learning_rate)\n# training parameters\nn_iters = 50000\nprint_every = 5000\nplot_every = 500\nall_losses = []\ntotal_loss = 0 # will be reset every 'plot_every' iterations\n\nstart = time.time()\n\nfor iter in range(1, n_iters + 1):\n    loss = train(*randomTrainingExample())\n    total_loss += loss\n\n    if iter % plot_every == 0:\n        all_losses.append(total_loss / plot_every)\n        total_loss = 0\n\n    if iter % print_every == 0:\n        rolling_mean = np.mean(all_losses[iter - print_every*(iter//print_every):])\n        print('%s (%d %d%%) %.4f' % (timeSince(start),\n                                     iter,\n                                     iter / n_iters * 100,\n                                     rolling_mean))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "## Plotting training performance\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [
        {
          "data": {
            "image/png": "",
            "text/plain": "<matplotlib.figure.Figure>"
          },
          "metadata": {
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "##################################################\n## monitoring loss function during training\n##################################################\n\nplt.figure()\nplt.plot(all_losses)\nplt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "## Evaluation\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "Extraction of surprisal of a single item and computation of average surprisal for test and training set is largely parallel to the case of sheet 5.1.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [],
      "source": [
        "##################################################\n## evaluation\n##################################################\n\ndef get_surprisal_item(category, name):\n    name      = torch.tensor(getNameIndices(name))\n    cat       = getCatIndices(category,len(name))\n    hidden    = lstm.initHidden()\n    prediction, hidden = lstm(cat, name, hidden)\n    nll       = criterion(prediction[:-1], name[1:len(name)])\n    return(nll.item())\n\ndef get_surprisal_dataset(data):\n    surprisl_dict = dict()\n    surp_avg_dict = dict()\n    perplxty_dict = dict()\n    for category in list(data.keys()):\n        surprisl = 0\n        surp_avg = 0\n        perplxty = 0\n        # training\n        for name in data[category]:\n            item_surpr = get_surprisal_item(category, name)\n            surprisl  += item_surpr\n            surp_avg  += item_surpr / len(name)\n            perplxty  += item_surpr ** (-1 / len(name))\n        n_items = len(data[category])\n\n        surprisl_dict[category] = (surprisl /n_items)\n        surp_avg_dict[category] = (surp_avg / n_items)\n        perplxty_dict[category] = (perplxty / n_items)\n\n    return(surprisl_dict, surp_avg_dict, perplxty_dict)\n\ndef makeDF(surp_dict):\n    p = pandas.DataFrame.from_dict(surp_dict)\n    p = p.transpose()\n    p.columns = [\"surprisal\", \"surp_scaled\", \"perplexity\"]\n    return(p)\n\nsurprisal_test  = makeDF(get_surprisal_dataset(test_data))\nsurprisal_train = makeDF(get_surprisal_dataset(train_data))\n\nprint(\"\\nmean surprisal (test):\", np.mean(surprisal_test[\"surprisal\"]))\nprint(\"\\nmean surprisal (train):\", np.mean(surprisal_train[\"surprisal\"]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 6.2.2: Interpret the evaluation metrics </span></strong>\n>\n> 1. What do you conclude from these two numbers? Is there a chance that the model overfitted the training data?\n>\n> 2. What do you conclude about the performance of the RNN (from sheet 5.1) and the current LSTM implementation? Which model is better?\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "## Exploring model predictions\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "Now the fun part starts!\nLet&rsquo;s see how the generations of the LSTM look like.\nNotice that there is a flag for the kind of decoding strategy to be used.\nCurrently, there are two decoding strategies (but see exercise below).\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [],
      "source": [
        "##################################################\n## prediction function\n##################################################\n\nmax_length = 20\n\n# make a prediction based on given sequence\ndef predict(category, initial_sequence, decode_strat = \"greedy\"):\n\n    if len(initial_sequence) >= max_length:\n        return(initial_sequence)\n\n    name      = torch.tensor(getNameIndices(initial_sequence))[:-1]\n    cat       = getCatIndices(category,len(name))\n    hidden    = lstm.initHidden()\n\n    generation = initial_sequence\n\n    output, hidden = lstm(cat, name, hidden)\n    next_word_pred = output[-1]\n\n    if decode_strat == \"pure\":\n        sample_index = torch.multinomial(input = torch.exp(next_word_pred),\n                                         num_samples = 1)\n        pass\n    else:\n        topv, topi = next_word_pred.topk(1)\n        sample_index = topi[0].item()\n\n    if sample_index == EOSIndex:\n        return(generation)\n    else:\n        generation += all_letters[sample_index]\n\n    return(predict(category, generation))\n\nprint(predict(\"German\", \"\", decode_strat = \"greedy\"))\nprint(predict(\"German\", \"\", decode_strat = \"pure\"))\nprint(predict(\"German\", \"\", decode_strat = \"pure\"))\nprint(predict(\"German\", \"\", decode_strat = \"pure\"))\n\nprint(predict(\"Japanese\", \"\", decode_strat = \"greedy\"))\nprint(predict(\"Japanese\", \"\", decode_strat = \"pure\"))\nprint(predict(\"Japanese\", \"\", decode_strat = \"pure\"))\nprint(predict(\"Japanese\", \"\", decode_strat = \"pure\"))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 6.2.3: Predictions under different decoding schemes </span></strong>\n>\n> 0. [Just for yourself] Play around with the prediction function. Are you content with the quality of the predictions? Is the model performing better than the previous RNN in your perception?\n>\n> 1. Extend the function &rsquo;predict&rsquo; by implementing three additional decoding schemes: top-k, softmax and top-p. Write the function in such a way that the decoding strategy can be chosen by the user with a mnemonic string (like already don for the &ldquo;pure&rdquo; decoding strategy).\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "## [Excursion] Class predictions from the generation model\n\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "In the previous sheet 5.1 we looked at a way of using the string generation probabilities for categorization.\nHere is a function that does that, too, but now for the LSTM model.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
      },
      "outputs": [],
      "source": [
        "def infer_category(name):\n    probs = torch.tensor([torch.exp(-torch.tensor(get_surprisal_item(c, name))) for c in categories])\n    probs = probs/torch.sum(probs)\n    vals, cats = probs.topk(3)\n    print(\"Top 3 guesses for \", name, \":\\n\")\n    for i in range(len(cats)):\n        print(\"%12s: %.5f\" %\n              (categories[cats[i]], vals[i].detach().numpy() ))\n\ninfer_category(\"Smith\")\ninfer_category(\"Miller\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
      },
      "source": [
        "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 6.2.4: Reflect on derived category predictions </span></strong>\n>\n> 1. [This is a bonus exercise; optional!] Check out the model&rsquo;s predictions for &ldquo;Smith&rdquo; and &ldquo;Miller&rdquo;. Is this what you would expect of a categorization function? Why? Why not? Can you explain why the this &ldquo;derived categorization model&rdquo; makes these predictions?\n\n"
      ]
    }
  ],
  "metadata": {
    "org": null,
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.5.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
