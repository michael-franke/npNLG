
# Artificial neural networks

In this session we learn about artificial neural networks.


## Learning goals for this session

1.  Become familiar with ANNs:
    1.  mathematical notation in matrix-vector form
    2.  weights & biases (slopes & intercepts), score, activation function, hidden layers, prediction
2.  Be able to use PyTorch to implement a feed-forward ANN:
    1.  building the model by hand
    2.  using built-in helper functions (nn.Module, DataLoader â€¦)

This unit requires basic familiarity with concepts and notation from linear algebra.
To recap, there is a short section on [algebra recap](https://michael-franke.github.io/npNLG/04b-algebra.html) with a handout and some further references.


## Slides

Here are the [slides for this session](<https://michael-franke.github.io/npNLG/04-neural-basics.pdf>).


## Practical exercises

There are two notebooks for exercises. First, we will implement a multi-layer feed-forward network &ldquo;[by hand](https://michael-franke.github.io/npNLG/04c-MLP-custom.html)&rdquo;. Then, we will implement the same model (for the same training data) by [using PyTorch&rsquo;s helper functions](https://michael-franke.github.io/npNLG/04d-MLP-pytorch.html).

