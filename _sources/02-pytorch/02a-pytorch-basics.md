
# Basics of PyTorch

PyTorch is a high-level framework for machine learning based on [torch](http://torch.ch/).
Modern ML techniques, such as artificial neural networks, require efficient computations of algebraic operations on large and high-dimensional tensors.
PyTorch offers a tensor-based computing framework that is optimized for exactly these kinds of computations.
Moreover, PyTorch offers ready-made modules for building complex ANNs.
A powerful automatic differentiation system, makes training these networks possible.

There are other similar libraries on the market (e.g., tensorflow), but PyTorch has been particularly popular in the NLP community.


## Learning goals for this session

1.  Understand what PyTorch is good for.
2.  Ability to create, access and manipulate tensors.
3.  Understand parameterized model predictions.
4.  Understand of what ‘parameter optimization’ is.
5.  Ability to use stochastic gradient descent to optimize parameters in PyTorch.


## Slides

Here are the [slides for this session](<https://michael-franke.github.io/npNLG/02-PyTorch.pdf>).


## Practical exercises

There are two notebooks for exercises: one on [basics of PyTorch](https://michael-franke.github.io/npNLG/02b-pytorch-intro.html), the other on [maximum likelihood estimation](https://michael-franke.github.io/npNLG/02c-MLE.html).
You can also find the extracted Python code for both notebooks on the [GitHub repository](https://github.com/michael-franke/npNLG) for this web-book.


## Slides

Here are the [slides for this session](<https://michael-franke.github.io/npNLG/02-PyTorch.pdf>).


## Resources

-   [Official PyTorch website](https://pytorch.org/) for information on installation
-   [Official PyTorch tutorials](https://pytorch.org/tutorials/)

