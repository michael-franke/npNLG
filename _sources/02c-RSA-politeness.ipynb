{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sheet 1.2: RSA with politeness\n",
    "==============================\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a (numpy-based) Python implementation of an RSA model with a speaker who has two weighted objectives:\n",
    "(i) being informative about the true world state and\n",
    "(ii) being polite.\n",
    "The latter is taken to mean that the speaker wants to increase the listener&rsquo;s degrees of beliefs in particular world states even if they are not true.\n",
    "\n",
    "The same model is also covered in [chapter 9 of problang.org](http://www.problang.org/chapters/09-politeness.html) (Scontras et. al 2018).\n",
    "The model covered here is essentially that of [Yoon et al. (2016)](http://langcog.stanford.edu/papers_new/yoon-2016-cogsci.pdf).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages & helper functions\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the same kinds of packages as before.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, we use the same helper functions as in Sheet 1.1 for computing soft-max and normalization of array dimensions.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "## helper functions\n",
    "##################################################\n",
    "\n",
    "def softmax(x, axis=1):\n",
    "    \"\"\"\n",
    "    Softmax function in numpy\n",
    "    Parameters\n",
    "    ----------\n",
    "    x: array\n",
    "        An array with any dimensionality\n",
    "    axis: int\n",
    "        The axis along which to apply the softmax\n",
    "    Returns\n",
    "    -------\n",
    "    array\n",
    "        Same shape as x\n",
    "    \"\"\"\n",
    "    e_x = np.exp(x - np.max(x, axis, keepdims=True))\n",
    "    return e_x / e_x.sum(axis=axis, keepdims=True)\n",
    "\n",
    "\n",
    "def normalize(arr, axis=1):\n",
    "    \"\"\"\n",
    "    Normalize arr along axis\n",
    "    \"\"\"\n",
    "    return arr / arr.sum(axis, keepdims=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running example\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a running example, we consider a context in which the speaker reports on their impression of the quality of the listener&rsquo;s self-baked cookies.\n",
    "\n",
    "We assume that there are five world states, represented as increasing integers.\n",
    "These numbers represent the true quality of the cookies (as perceived by the speaker).\n",
    "\n",
    "We also assume that there are five expressions the speaker might want to use to report their quality assessment.\n",
    "The semantic meaning we use for these expressions is a &ldquo;soft-semantics&rdquo; (truth-values are not confined to 0 and 1), which are derived from an experiment designed to elicit participants intuitions about the relevant semantic meanings ([Yoon et al. 2016](http://langcog.stanford.edu/papers_new/yoon-2016-cogsci.pdf)).\n",
    "\n",
    "[Q: does only the ordering or also the equally-spaced distance matter to the model?]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "## defining the context\n",
    "##################################################\n",
    "\n",
    "states     = [1,2,3,4,5]\n",
    "utterances = [\"terrible\",\"bad\",\"okay\",\"good\",\"amazing\"]\n",
    "\n",
    "semantic_meaning = np.array(\n",
    "    [[.95 ,.85 ,.02 ,.02,.02],    # terrible\n",
    "     [.85 ,.95 ,.02 ,.02,.02],    # bad\n",
    "     [.02 ,.25 ,.95 ,.65,.35],    # okay\n",
    "     [.02 ,.05 ,.55 ,.95,.93],    # good\n",
    "     [.02 ,.02 ,.02 ,.65,.95]]    # amazing\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <strong><span style=&ldquo;color:#D83D2B;&rdquo;>Exercise 1.2.1: Check experiment and your intuitions</span></strong>\n",
    ">\n",
    "> 1. Consult the original paper ([Yoon et al. 2016](http://langcog.stanford.edu/papers_new/yoon-2016-cogsci.pdf)) to find the description of the experiment that was used to get these semantic values. Describe this experiment in at most three simple sentences: what was the question participants had to answer and how were answers recorded?\n",
    "> 2. Comment on whether you find the obtained values intuitive **as values of the semantic meaning of these expression**.\n",
    "> 3. Do you think that the experiment was well-designed for the task of eliciting information about semantic meaning of expressions?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The model and its parameters\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model definition\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "## model parameters\n",
    "##################################################\n",
    "\n",
    "alpha        = 10\n",
    "phi          = 0.99\n",
    "social_value = 1.25\n",
    "\n",
    "##################################################\n",
    "## RSA speaker with politeness\n",
    "##################################################\n",
    "\n",
    "def RSA_polite_speaker(alpha, phi, social_value):\n",
    "    \"\"\"\n",
    "    predictions of an RSA model with politeness (speaker part)\n",
    "    (following: http://www.problang.org/chapters/09-politeness.html)\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha: float\n",
    "        Optimality parameter\n",
    "    phi: float\n",
    "        Relative weight of epistemic utility component\n",
    "    social_value: float\n",
    "        Social value factor (how much more \"socially valuable\" is one more star?)\n",
    "    Returns\n",
    "    -------\n",
    "    array\n",
    "        probability that speaker chooses utterance for each state\n",
    "    \"\"\"\n",
    "    literal_listener   = normalize(semantic_meaning)\n",
    "    epistemic_utility  = np.log(np.transpose(literal_listener))\n",
    "    social_utility     = np.sum(literal_listener * np.array([states]) * social_value, axis=1)\n",
    "    util_speaker       = phi * epistemic_utility + (1-phi) * social_utility\n",
    "    pragmatic_speaker  = softmax(alpha * util_speaker)\n",
    "    return(pragmatic_speaker)\n",
    "\n",
    "RSA_speaker_predictions = RSA_polite_speaker(alpha, phi, social_value)\n",
    "\n",
    "speaker  = pd.DataFrame(data    = RSA_speaker_predictions,\n",
    "                        index   = states,\n",
    "                        columns = utterances)\n",
    "speaker['object'] = speaker.index\n",
    "\n",
    "print(speaker.round(2))\n",
    "\n",
    "speaker_long = speaker.melt(id_vars      = \"object\",\n",
    "                            var_name     = \"utterance\",\n",
    "                            value_name   = \"probability\",\n",
    "                            ignore_index = False)\n",
    "speaker_plot = sns.FacetGrid(speaker_long, col=\"object\")\n",
    "speaker_plot.map(sns.barplot, \"utterance\", \"probability\")\n",
    "plt.show()\n",
    "\n",
    "# Exercises:\n",
    "# - Change the call to the speaker to make it so that it only cares about making the listener feel good.\n",
    "# - Change the call to the speaker to make it so that it cares about both making the listener feel good and conveying information.\n",
    "# - Change the value of the social_value and examine the results.\n",
    "\n",
    "##################################################\n",
    "## pragmatic listener infers politeness level\n",
    "##################################################\n",
    "\n",
    "# which phi-values to consider\n",
    "phi_marks     = np.linspace(start=0, stop=1, num=11)\n",
    "phi_prior_flt = np.array([1,1,1,1,1,1,1,1,1,1,1])   # flat\n",
    "phi_prior_bsd = np.array([1,2,3,4,5,6,7,8,9,10,11]) # biased towards politeness\n",
    "\n",
    "def RSA_polite_listener(alpha, phi_prior, social_value):\n",
    "    \"\"\"\n",
    "    predictions of an RSA model with politeness (listener part)\n",
    "    (following: http://www.problang.org/chapters/09-politeness.html)\n",
    "    Parameters\n",
    "    ----------\n",
    "    alpha: float\n",
    "        Optimality parameter\n",
    "    phi_priors: float\n",
    "        Prior over degree of politeness (phi-parameter)\n",
    "    social_value: float\n",
    "        Social value factor (how much more \"socially valuable\" is one more star?)\n",
    "    Returns\n",
    "    -------\n",
    "    array\n",
    "         for each message: listener posterior over state-phi pairs\n",
    "    \"\"\"\n",
    "    phi_prior = phi_prior / np.sum(phi_prior) # make sure priors are normalized\n",
    "    posterior = np.zeros((len(phi_marks), len(utterances),len(states)))\n",
    "    for i in range(len(phi_marks)):\n",
    "        pragmatic_speaker  = RSA_polite_speaker(alpha, phi_marks[i], social_value)\n",
    "        posterior[i,:,:]   = np.transpose(pragmatic_speaker) * phi_prior[i]\n",
    "    return(normalize(posterior, axis=(0,1)))\n",
    "\n",
    "RSA_listener_predictions = RSA_polite_listener(alpha, phi_prior_flt, social_value)\n",
    "\n",
    "print(\"listener posterior over states after hearing 'amazing':\\n\",\n",
    "      np.sum(RSA_listener_predictions[:,:,4], axis=0))\n",
    "\n",
    "# TODO: why are the values numerically slightly off wrt to the WebPPL implementation?\n",
    "# TODO: cast the 3D array into DataFrame for plotting\n",
    "\n",
    "iterables=[phi_marks, utterances, states]\n",
    "index = pd.MultiIndex.from_product(iterables, names=['phi','utterance','state'])\n",
    "\n",
    "listener = pd.DataFrame(RSA_listener_predictions.reshape(RSA_listener_predictions.size, 1),\n",
    "                        index=index)\n",
    "listener = listener.reset_index()\n",
    "\n",
    "##################################################\n",
    "## plotting the results\n",
    "##################################################\n",
    "\n",
    "def plot_listener(utterance_index):\n",
    "    print(\"plotting listener posterior for utterance:\", utterances[utterance_index])\n",
    "    predictions = RSA_listener_predictions[:,utterance_index,:]\n",
    "    sns.heatmap(predictions)\n",
    "    plt.show()\n",
    "\n",
    "plot_listener(3)\n",
    "\n",
    "# Exercises:\n",
    "# 1. Use the plotting function for different indeces (0-4). What is plotted here?\n",
    "#    What's on the x-axis, the y-axis, and what do the colors mean?\n",
    "# 2. Plot the results for the utterance \"good\". Describe the result in your own words.\n",
    "#    Comment on whether this makes sense to you, i.e., is the result an intuitive / natural\n",
    "#    interpretation of such an utterance (in the context we assume here)?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scontras, G., Tessler, M. H., & Franke, M. (2018). [Probabilistic language understanding: An introduction to the Rational Speech Act framework](http://www.problang.org).\n",
    "\n",
    "Yoon, E. J., Tessler, M. H., Goodman, N. D., & Frank, M. C. (2016). [Talking with tact: polite language as a balance between kindness and informativity](http://langcog.stanford.edu/papers_new/yoon-2016-cogsci.pdf). In: *Proceedings of CogSci* 38.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "org": null
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
